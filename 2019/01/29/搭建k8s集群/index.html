<!DOCTYPE html>
<html>
<head>
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>手动搭建k8s集群 | Neo42 | Dont&#39;t Panic,Do not go gentle into that good night :)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="Technology">
    <meta name="description" content="集群节点 初始化1略 集群环境变量&amp;amp;节点分发12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x">
<meta name="keywords" content="Technology">
<meta property="og:type" content="article">
<meta property="og:title" content="手动搭建k8s集群">
<meta property="og:url" content="https://yo42.github.io/2019/01/29/搭建k8s集群/index.html">
<meta property="og:site_name" content="Neo42">
<meta property="og:description" content="集群节点 初始化1略 集群环境变量&amp;amp;节点分发12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-04-23T08:25:06.129Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="手动搭建k8s集群">
<meta name="twitter:description" content="集群节点 初始化1略 集群环境变量&amp;amp;节点分发12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x">
    
        <link rel="alternate" type="application/atom+xml" title="Neo42" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide" >
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/yo.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Neo</h5>
          <a href="mailto:edyo7024@gmail.com" title="edyo7024@gmail.com" class="mail">edyo7024@gmail.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/"  >
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags"  >
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://yo42.github.io/Aobut-Me/"  >
                <i class="icon icon-lg icon-user"></i>
                About Me
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">手动搭建k8s集群</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">手动搭建k8s集群</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-01-29T02:34:08.394Z" itemprop="datePublished" class="page-time">
  2019-01-29
</time>


	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Technology/">Technology</a></li></ul>

            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#集群节点-初始化"><span class="post-toc-number">1.</span> <span class="post-toc-text">集群节点 初始化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#集群环境变量-amp-节点分发"><span class="post-toc-number">2.</span> <span class="post-toc-text">集群环境变量&amp;节点分发</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建CA证书和密钥-amp-节点分发"><span class="post-toc-number">3.</span> <span class="post-toc-text">创建CA证书和密钥&amp;节点分发</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#安装CFSSL工具集"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">安装CFSSL工具集</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#生成CA-证书和私钥："><span class="post-toc-number">3.2.</span> <span class="post-toc-text">生成CA 证书和私钥：</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#部署etcd集群-节点x3"><span class="post-toc-number">4.</span> <span class="post-toc-text">部署etcd集群 (节点x3)</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建TLS-密钥和证书"><span class="post-toc-number">5.</span> <span class="post-toc-text">创建TLS 密钥和证书</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建etcd-的systemd-unit-文件"><span class="post-toc-number">6.</span> <span class="post-toc-text">创建etcd 的systemd unit 文件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#启动etcd-服务"><span class="post-toc-number">7.</span> <span class="post-toc-text">启动etcd 服务</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#验证服务"><span class="post-toc-number">7.1.</span> <span class="post-toc-text">验证服务</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置kubectl-命令行工具"><span class="post-toc-number">7.2.</span> <span class="post-toc-text">配置kubectl 命令行工具</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建admin-证书"><span class="post-toc-number">7.3.</span> <span class="post-toc-text">创建admin 证书</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kubectl-kubeconfig-文件"><span class="post-toc-number">7.4.</span> <span class="post-toc-text">创建kubectl kubeconfig 文件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#分发kubeconfig-文件"><span class="post-toc-number">7.5.</span> <span class="post-toc-text">分发kubeconfig 文件</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#部署K8s-Master节点"><span class="post-toc-number">8.</span> <span class="post-toc-text">部署K8s Master节点</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kubernetes-证书"><span class="post-toc-number">8.1.</span> <span class="post-toc-text">创建kubernetes 证书</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#生成kubernetes-证书和私钥："><span class="post-toc-number">8.2.</span> <span class="post-toc-text">生成kubernetes 证书和私钥：</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置和启动kube-apiserver"><span class="post-toc-number">8.3.</span> <span class="post-toc-text">配置和启动kube-apiserver</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-apiserver-使用的客户端token-文件"><span class="post-toc-number">8.4.</span> <span class="post-toc-text">创建kube-apiserver 使用的客户端token 文件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-apiserver-的systemd-unit文件"><span class="post-toc-number">8.5.</span> <span class="post-toc-text">创建kube-apiserver 的systemd unit文件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#启动kube-apiserver"><span class="post-toc-number">8.6.</span> <span class="post-toc-text">启动kube-apiserver</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置和启动kube-controller-manager"><span class="post-toc-number">8.7.</span> <span class="post-toc-text">配置和启动kube-controller-manager</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#启动kube-controller-manager"><span class="post-toc-number">8.8.</span> <span class="post-toc-text">启动kube-controller-manager</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置和启动kube-scheduler"><span class="post-toc-number">8.9.</span> <span class="post-toc-text">配置和启动kube-scheduler</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-scheduler-的systemd-unit文件"><span class="post-toc-number">8.10.</span> <span class="post-toc-text">创建kube-scheduler 的systemd unit文件</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#启动kube-scheduler"><span class="post-toc-number">9.</span> <span class="post-toc-text">启动kube-scheduler</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-4-验证master-节点"><span class="post-toc-number"></span> <span class="post-toc-text">6.4 验证master 节点</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#关于k8s-master节点高可用"><span class="post-toc-number">1.</span> <span class="post-toc-text">关于k8s master节点高可用</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#方式1：使用阿里云SLB"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">方式1：使用阿里云SLB</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#方式2：使用keepalived"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">方式2：使用keepalived</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#安装haproxy、keepalived"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">安装haproxy、keepalived</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置haproxy"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">配置haproxy</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#启动haproxy"><span class="post-toc-number">1.5.</span> <span class="post-toc-text">启动haproxy</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#kube-controller-manager-和kube-scheduler-的高可用"><span class="post-toc-number">1.6.</span> <span class="post-toc-text">kube-controller-manager 和kube-scheduler 的高可用</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#k8s-Node节点安装flannel网络"><span class="post-toc-number">2.</span> <span class="post-toc-text">k8s Node节点安装flannel网络</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建TLS-密钥和证书-1"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">创建TLS 密钥和证书</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#向etcd-写入集群Pod-网段信息"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">向etcd 写入集群Pod 网段信息</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#启动flanneld"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">启动flanneld</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#检查flanneld-服务"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">检查flanneld 服务</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#检查分配给各flanneld-的Pod-网段信息"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">检查分配给各flanneld 的Pod 网段信息</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#部署-K8s-Node节点"><span class="post-toc-number">3.</span> <span class="post-toc-text">部署 K8s Node节点</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#安装Docker基础环境"><span class="post-toc-number">3.1.</span> <span class="post-toc-text">安装Docker基础环境</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#配置docker"><span class="post-toc-number">3.2.</span> <span class="post-toc-text">配置docker</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#启动docker"><span class="post-toc-number">4.</span> <span class="post-toc-text">启动docker</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#安装和配置kubelet"><span class="post-toc-number">5.</span> <span class="post-toc-text">安装和配置kubelet</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建kubelet-bootstapping-kubeconfig-文件"><span class="post-toc-number">6.</span> <span class="post-toc-text">创建kubelet bootstapping kubeconfig 文件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#创建kubelet-的systemd-unit-文件"><span class="post-toc-number">7.</span> <span class="post-toc-text">创建kubelet 的systemd unit 文件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#启动kubelet"><span class="post-toc-number">8.</span> <span class="post-toc-text">启动kubelet</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#通过kubelet-的TLS-证书请求"><span class="post-toc-number">9.</span> <span class="post-toc-text">通过kubelet 的TLS 证书请求</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#配置kube-proxy"><span class="post-toc-number">10.</span> <span class="post-toc-text">配置kube-proxy</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-proxy-证书签名请求："><span class="post-toc-number">10.1.</span> <span class="post-toc-text">创建kube-proxy 证书签名请求：</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#生成kube-proxy-客户端证书和私钥"><span class="post-toc-number">10.2.</span> <span class="post-toc-text">生成kube-proxy 客户端证书和私钥</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-proxy-kubeconfig-文件"><span class="post-toc-number">10.3.</span> <span class="post-toc-text">创建kube-proxy kubeconfig 文件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#创建kube-proxy-的systemd-unit-文件"><span class="post-toc-number">10.4.</span> <span class="post-toc-text">创建kube-proxy 的systemd unit 文件</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#启动kube-proxy"><span class="post-toc-number">10.5.</span> <span class="post-toc-text">启动kube-proxy</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#验证集群功能"><span class="post-toc-number">11.</span> <span class="post-toc-text">验证集群功能</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#解决从k8s-gcr-io拉取镜像失败问题"><span class="post-toc-number">12.</span> <span class="post-toc-text">解决从k8s.gcr.io拉取镜像失败问题</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#参考资料"><span class="post-toc-number"></span> <span class="post-toc-text">参考资料</span></a>
        </nav>
    </aside>


<article id="post-搭建k8s集群"
  class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">手动搭建k8s集群</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-01-29 10:34:08" datetime="2019-01-29T02:34:08.394Z"  itemprop="datePublished">2019-01-29</time>

            
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/Technology/">Technology</a></li></ul>



            

        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h3 id="集群节点-初始化"><a href="#集群节点-初始化" class="headerlink" title="集群节点 初始化"></a>集群节点 初始化</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">略</span><br></pre></td></tr></table></figure>
<h3 id="集群环境变量-amp-节点分发"><a href="#集群环境变量-amp-节点分发" class="headerlink" title="集群环境变量&amp;节点分发"></a>集群环境变量&amp;节点分发</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"># TLS Bootstrapping 使用的Token，可以使用命令 head -c 16 /dev/urandom | od -An -t x | tr -d &apos; &apos; 生成</span><br><span class="line">BOOTSTRAP_TOKEN=&quot;a4b521597f9938eaf36a82177c7c6f3a&quot;</span><br><span class="line"></span><br><span class="line"># 最好使用 当前未用的网段 来定义服务网段和 Pod 网段</span><br><span class="line"></span><br><span class="line"># 服务网段，部署前路由不可达，部署后集群内路由可达(kube-proxy 和 ipvs 保证)</span><br><span class="line">export SERVICE_CIDR=&quot;10.100.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"># Pod 网段，建议 /16 段地址，部署前路由不可达，部署后集群内路由可达(flanneld 保证)</span><br><span class="line">export CLUSTER_CIDR=&quot;10.200.0.0/16&quot;</span><br><span class="line"></span><br><span class="line"># 服务端口范围 (NodePort Range)</span><br><span class="line">export NODE_PORT_RANGE=&quot;30000-32766&quot;</span><br><span class="line"></span><br><span class="line"># 集群各机器 IP 数组</span><br><span class="line">export NODE_IPS=&quot;10.1.2.30 10.1.2.1 10.1.2.2&quot;</span><br><span class="line">export NODE_IP=&quot;10.1.2.30&quot;</span><br><span class="line"></span><br><span class="line"># 集群各 IP 对应的 主机名数组</span><br><span class="line">export NODE_NAME=kube-master1</span><br><span class="line"></span><br><span class="line"># kube-apiserver 的 VIP（HA 组件 keepalived 发布的 IP）</span><br><span class="line">#export MASTER_VIP=172.27.129.253</span><br><span class="line"># MASTER API Server 地址</span><br><span class="line">MASTER_URL=&quot;hhht-k8s-api.virtual.local&quot;</span><br><span class="line"></span><br><span class="line"># kube-apiserver VIP 地址（HA 组件 haproxy 监听 6443 端口）</span><br><span class="line">export KUBE_APISERVER=&quot;https://$&#123;MASTER_URL&#125;:6443&quot;</span><br><span class="line"></span><br><span class="line"># HA 节点，配置 VIP 的网络接口名称</span><br><span class="line">#export VIP_IF=&quot;eth0&quot;</span><br><span class="line"></span><br><span class="line"># etcd 集群服务地址列表</span><br><span class="line">export ETCD_ENDPOINTS=&quot;https://10.1.2.30:2379,https://10.1.2.1:2379,https://10.1.2.2:2379&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># etcd 集群间通信的 IP 和端口</span><br><span class="line">export ETCD_NODES=&quot;kube-master1=https://10.1.2.30:2380,kube-master2=https://10.1.2.1:2380,kube-master3=https://10.1.2.2:2380&quot;</span><br><span class="line"></span><br><span class="line"># flanneld 网络配置前缀</span><br><span class="line">export FLANNEL_ETCD_PREFIX=&quot;/kubernetes/network&quot;</span><br><span class="line"></span><br><span class="line"># kubernetes 服务IP(预先分配，一般为SERVICE_CIDR中的第一个IP)</span><br><span class="line">export CLUSTER_KUBERNETES_SVC_IP=&quot;10.100.0.1&quot;</span><br><span class="line"></span><br><span class="line"># 集群 DNS 服务IP(从SERVICE_CIDR 中预先分配)</span><br><span class="line">export CLUSTER_DNS_SVC_IP=&quot;10.100.0.2&quot;</span><br><span class="line"></span><br><span class="line"># 集群 DNS 域名</span><br><span class="line">export CLUSTER_DNS_DOMAIN=&quot;hhhtcluster.local.&quot;</span><br><span class="line"></span><br><span class="line"># 将二进制目录 /opt/k8s/bin 加到 PATH 中</span><br><span class="line">PATH=/usr/k8s/bin:$PATH</span><br><span class="line"></span><br><span class="line">PATH=/apps/svr/k8s/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>复制到所有服务器上给以上文件执行权限然后修改系统变量</p>
<p>echo ‘source /apps/sh/env.sh’ &gt;&gt; ~/.bash_profile</p>
<p>将上面变量保存为: env.sh，然后将脚本拷贝到所有机器的/apps/sh/目录。</p>
<p>为方便后面迁移，我们在集群内定义一个域名用于访问apiserver，在每个节点的/etc/hosts文件中添加记录：10.1.2.30 hhht-k8s-api.virtual.local</p>
<p>其中10.1.2.30为master01 的IP，暂时使用该IP 来做apiserver 的负载地址</p>
<h3 id="创建CA证书和密钥-amp-节点分发"><a href="#创建CA证书和密钥-amp-节点分发" class="headerlink" title="创建CA证书和密钥&amp;节点分发"></a>创建CA证书和密钥&amp;节点分发</h3><h4 id="安装CFSSL工具集"><a href="#安装CFSSL工具集" class="headerlink" title="安装CFSSL工具集"></a>安装CFSSL工具集</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">chmod +x cfssl_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 /usr/local/bin/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">chmod +x cfssljson_linux-amd64</span><br><span class="line">mv cfssljson_linux-amd64 /usr/local/bin/cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">chmod +x cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl-certinfo_linux-amd64 /usr/local/bin/cfssl-certinfo</span><br><span class="line"></span><br><span class="line">export PATH=/usr/local/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>创建目录 mkdir -p /apps/conf/kubernetes/ssl</p>
<p>进入/apps/conf/kubernetes/ssl 目录新建以下2个文件</p>
<p>ca-config.json、ca-csr.json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;signing&quot;: &#123;</span><br><span class="line">        &quot;default&quot;: &#123;</span><br><span class="line">            &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;profiles&quot;: &#123;</span><br><span class="line">            &quot;kubernetes&quot;: &#123;</span><br><span class="line">                &quot;expiry&quot;: &quot;87600h&quot;,</span><br><span class="line">                &quot;usages&quot;: [</span><br><span class="line">                    &quot;signing&quot;,</span><br><span class="line">                    &quot;key encipherment&quot;,</span><br><span class="line">                    &quot;server auth&quot;,</span><br><span class="line">                    &quot;client auth&quot;</span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>config.json</code>：可以定义多个profiles，分别指定不同的过期时间、使用场景等参数；后续在签名证书时使用某个profile；</li>
<li><code>signing</code>: 表示该证书可用于签名其它证书；生成的ca.pem 证书中<code>CA=TRUE</code>；</li>
<li><code>server auth</code>: 表示client 可以用该CA 对server 提供的证书进行校验；</li>
<li><code>client auth</code>: 表示server 可以用该CA 对client 提供的证书进行验证。</li>
</ul>
<p>ca-csr.json</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">    &quot;key&quot;: &#123;</span><br><span class="line">        &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">        &quot;size&quot;: 2048</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;names&quot;: [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">            &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">            &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">            &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><code>CN</code>: <code>Common Name</code>，kube-apiserver 从证书中提取该字段作为请求的用户名(User Name)；浏览器使用该字段验证网站是否合法；</li>
<li><code>O</code>: <code>Organization</code>，kube-apiserver 从证书中提取该字段作为请求用户所属的组(Group)；</li>
</ul>
<h4 id="生成CA-证书和私钥："><a href="#生成CA-证书和私钥：" class="headerlink" title="生成CA 证书和私钥："></a>生成CA 证书和私钥：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca</span><br><span class="line">ls` `ca*</span><br><span class="line">ca-config.json  ca.csr  ca-csr.json  ca-key.pem  ca.pem</span><br></pre></td></tr></table></figure>
<p>创建完成后把/apps/conf/kubernetes/ssl这个目录复制到所有master节点上</p>
<h3 id="部署etcd集群-节点x3"><a href="#部署etcd集群-节点x3" class="headerlink" title="部署etcd集群 (节点x3)"></a>部署etcd集群 (节点x3)</h3><p>kubernetes 系统使用etcd存储所有的数据，我们这里部署3个节点的etcd 集群，这3个节点直接复用kubernetes master的3个节点，分别命名为etcd01、etcd02、etcd03:</p>
<p>etcd01：10.1.2.30<br>etcd02：10.1.2.1<br>etcd03：10.1.2.2</p>
<p>修改3台master服务器的/apps/sh/env.sh文件的第31行左右</p>
<p>把以下内容修改为本机信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">####OTHER</span><br><span class="line">NODE_NAME=etcd01</span><br><span class="line">NODE_IP=10.1.2.30</span><br></pre></td></tr></table></figure>
<p>名字可以任意只要能区分就可以</p>
<p>IP填写本机IP</p>
<p>修改以下配置填入所有正确的ETCD地址</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">NODE_IPS=&quot;172.18.49.242 172.18.49.243 172.18.49.244&quot;</span><br><span class="line"></span><br><span class="line">ETCD_NODES=etcd01=https://172.18.49.242:2380,etcd02=https://172.18.49.243:2380,etcd03=https://172.18.49.244:2380</span><br><span class="line"></span><br><span class="line">KUBE_APISERVER=&quot;https://$&#123;MASTER_URL&#125;:6443&quot;</span><br></pre></td></tr></table></figure>
<p>修改完毕后执行 source /apps/sh/env.sh 命令</p>
<p>echo $NODE_NAME</p>
<p>echo $NODE_IP</p>
<p>echo $ETCD_NODES</p>
<p>输出内容是你修改的内容即正确。</p>
<h3 id="创建TLS-密钥和证书"><a href="#创建TLS-密钥和证书" class="headerlink" title="创建TLS 密钥和证书"></a>创建TLS 密钥和证书</h3><p>为了保证通信安全，客户端(如etcdctl)与etcd 集群、etcd 集群之间的通信需要使用TLS 加密。</p>
<p>创建etcd 证书签名请求：</p>
<p>对应路径：/apps/conf/etcd/ssl</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;$&#123;NODE_IP&#125;&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>生成证书</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/apps/conf/kubernetes/ssl/ca.pem   -ca-key=/apps/conf/kubernetes/ssl/ca-key.pem   -config=/apps/conf/kubernetes/ssl/ca-config.json   -profile=kubernetes etcd-csr.json | cfssljson -bare etcd</span><br></pre></td></tr></table></figure>
<h3 id="创建etcd-的systemd-unit-文件"><a href="#创建etcd-的systemd-unit-文件" class="headerlink" title="创建etcd 的systemd unit 文件"></a>创建etcd 的systemd unit 文件</h3><p>需要新建目录 /apps/lib/etcd/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">Documentation=https://github.com/coreos</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=/apps/lib/etcd/</span><br><span class="line">ExecStart=/apps/svr/k8s/bin/etcd \\</span><br><span class="line">  --name=$&#123;NODE_NAME&#125; \\</span><br><span class="line">  --cert-file=/apps/conf/etcd/ssl/etcd.pem \\</span><br><span class="line">  --key-file=/apps/conf/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --peer-cert-file=/apps/conf/etcd/ssl/etcd.pem \\</span><br><span class="line">  --peer-key-file=/apps/conf/etcd/ssl/etcd-key.pem \\</span><br><span class="line">  --trusted-ca-file=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --peer-trusted-ca-file=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --initial-advertise-peer-urls=https://$&#123;NODE_IP&#125;:2380 \\</span><br><span class="line">  --listen-peer-urls=https://$&#123;NODE_IP&#125;:2380 \\</span><br><span class="line">  --listen-client-urls=https://$&#123;NODE_IP&#125;:2379,http://127.0.0.1:2379 \\</span><br><span class="line">  --advertise-client-urls=https://$&#123;NODE_IP&#125;:2379 \\</span><br><span class="line">  --initial-cluster-token=etcd-cluster-0 \\</span><br><span class="line">  --initial-cluster=$&#123;ETCD_NODES&#125; \\</span><br><span class="line">  --initial-cluster-state=new \\</span><br><span class="line">  --data-dir=/apps/lib/etcd</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>指定<code>etcd</code>的工作目录和数据目录为 /apps/lib/etcd/，需要在启动服务前创建这个目录；</li>
<li>为了保证通信安全，需要指定etcd 的公私钥(cert-file和key-file)、Peers通信的公私钥和CA 证书(peer-cert-file、peer-key-file、peer-trusted-ca-file)、客户端的CA 证书(trusted-ca-file)；</li>
<li><code>--initial-cluster-state</code>值为<code>new</code>时，<code>--name</code>的参数值必须位于<code>--initial-cluster</code>列表中；</li>
</ul>
<h3 id="启动etcd-服务"><a href="#启动etcd-服务" class="headerlink" title="启动etcd 服务"></a>启动etcd 服务</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp etcd.service /etc/systemd/system/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable etcd</span><br><span class="line">systemctl start etcd</span><br><span class="line">systemctl status etcd</span><br></pre></td></tr></table></figure>
<p>最先启动的etcd 进程会卡住一段时间，等待其他节点启动加入集群，在所有的etcd 节点重复上面的步骤，直到所有的机器etcd 服务都已经启动。</p>
<h4 id="验证服务"><a href="#验证服务" class="headerlink" title="验证服务"></a>验证服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for ip in $&#123;NODE_IPS&#125;; do</span><br><span class="line">  ETCDCTL_API=3 /apps/svr/k8s/bin/etcdctl \</span><br><span class="line">  --endpoints=https://$&#123;ip&#125;:2379  \</span><br><span class="line">  --cacert=/apps/conf/kubernetes/ssl/ca.pem \</span><br><span class="line">  --cert=/apps/conf/etcd/ssl/etcd.pem \</span><br><span class="line">  --key=/apps/conf/etcd/ssl/etcd-key.pem \</span><br><span class="line">  endpoint health; done</span><br></pre></td></tr></table></figure>
<p><a href="https://10.1.2.30:2379" target="_blank" rel="noopener">https://10.1.2.30:2379</a> is healthy: successfully committed proposal: took = 2.436477ms<br><a href="https://10.1.2.1:2379" target="_blank" rel="noopener">https://10.1.2.1:2379</a> is healthy: successfully committed proposal: took = 2.893396ms<br><a href="https://10.1.2.2:2379" target="_blank" rel="noopener">https://10.1.2.2:2379</a> is healthy: successfully committed proposal: took = 2.621429ms</p>
<h4 id="配置kubectl-命令行工具"><a href="#配置kubectl-命令行工具" class="headerlink" title="配置kubectl 命令行工具"></a>配置kubectl 命令行工具</h4><p>在master服务器上安装</p>
<p>kubectl默认从~/.kube/config配置文件中获取访问kube-apiserver 地址、证书、用户名等信息，需要正确配置该文件才能正常使用kubectl命令。</p>
<p>需要将下载的kubectl 二进制文件和生产的~/.kube/config配置文件拷贝到需要使用kubectl 命令的机器上。</p>
<h4 id="创建admin-证书"><a href="#创建admin-证书" class="headerlink" title="创建admin 证书"></a>创建admin 证书</h4><p>kubectl 与kube-apiserver 的安全端口通信，需要为安全通信提供TLS 证书和密钥。创建admin 证书签名请求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;admin&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;system:masters&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>后续kube-apiserver使用RBAC 对客户端(如kubelet、kube-proxy、Pod)请求进行授权<br>kube-apiserver 预定义了一些RBAC 使用的RoleBindings，如cluster-admin 将Group system:masters与Role cluster-admin绑定，该Role 授予了调用kube-apiserver所有API 的权限<br>O 指定了该证书的Group 为system:masters，kubectl使用该证书访问kube-apiserver时，由于证书被CA 签名，所以认证通过，同时由于证书用户组为经过预授权的system:masters，所以被授予访问所有API 的劝降<br>hosts 属性值为空列表</p>
<p>新建目录/apps/conf/kubectl/ssl 在目录中生成admin 证书和私钥：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/apps/conf/kubernetes/ssl/ca.pem   -ca-key=/apps/conf/kubernetes/ssl/ca-key.pem   -config=/apps/conf/kubernetes/ssl/ca-config.json   -profile=kubernetes admin-csr.json | cfssljson -bare admin</span><br></pre></td></tr></table></figure>
<h4 id="创建kubectl-kubeconfig-文件"><a href="#创建kubectl-kubeconfig-文件" class="headerlink" title="创建kubectl kubeconfig 文件"></a>创建kubectl kubeconfig 文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl config set-cluster kubernetes   --certificate-authority=/apps/conf/kubernetes/ssl/ca.pem   --embed-certs=true   --server=$&#123;KUBE_APISERVER&#125;</span><br><span class="line">kubectl config set-credentials admin   --client-certificate=/apps/conf/kubectl/ssl/admin.pem   --embed-certs=true   --client-key=/apps/conf/kubectl/ssl/admin-key.pem   --token=$&#123;BOOTSTRAP_TOKEN&#125;</span><br><span class="line">kubectl config set-context kubernetes   --cluster=kubernetes   --user=admin</span><br><span class="line">kubectl config use-context kubernetes</span><br></pre></td></tr></table></figure>
<p>admin.pem证书O 字段值为system:masters，kube-apiserver 预定义的 RoleBinding cluster-admin 将 Group system:masters 与 Role cluster-admin 绑定，该 Role 授予了调用kube-apiserver 相关 API 的权限<br>生成的kubeconfig 被保存到 ~/.kube/config 文件</p>
<p>注意这里是配置连接信息的。如果发现连接不通可以到 ~/.kube/config 这里查看服务器配置是否都正确</p>
<h4 id="分发kubeconfig-文件"><a href="#分发kubeconfig-文件" class="headerlink" title="分发kubeconfig 文件"></a>分发kubeconfig 文件</h4><p>将~/.kube/config文件拷贝到运行kubectl命令的机器的~/.kube/目录下去。</p>
<h3 id="部署K8s-Master节点"><a href="#部署K8s-Master节点" class="headerlink" title="部署K8s Master节点"></a>部署K8s Master节点</h3><p>kubernetes master 节点包含的组件有：</p>
<p>kube-apiserver<br>kube-scheduler<br>kube-controller-manager</p>
<p>目前这3个组件需要部署到同一台机器上：（后面再部署高可用的master）</p>
<p>kube-scheduler、kube-controller-manager 和 kube-apiserver 三者的功能紧密相关；<br>同时只能有一个 kube-scheduler、kube-controller-manager 进程处于工作状态，如果运行多个，则需要通过选举产生一个 leader；</p>
<p>master 节点与node 节点上的Pods 通过Pod 网络通信，所以需要在master 节点上部署Flannel 网络。</p>
<h4 id="创建kubernetes-证书"><a href="#创建kubernetes-证书" class="headerlink" title="创建kubernetes 证书"></a>创建kubernetes 证书</h4><p>创建kubernetes 证书签名请求：</p>
<p>进入目录  /apps/conf/kubernetes/ssl</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubernetes-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;$&#123;NODE_IP&#125;&quot;,</span><br><span class="line">    &quot;$&#123;MASTER_URL&#125;&quot;,</span><br><span class="line">    &quot;$&#123;CLUSTER_KUBERNETES_SVC_IP&#125;&quot;,</span><br><span class="line">    &quot;kubernetes&quot;,</span><br><span class="line">    &quot;kubernetes.default&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster&quot;,</span><br><span class="line">    &quot;kubernetes.default.svc.cluster.local&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>如果 hosts 字段不为空则需要指定授权使用该证书的 <strong>IP 或域名列表</strong>，所以上面分别指定了当前部署的 master 节点主机 IP 以及apiserver 负载的内部域名</li>
<li>还需要添加 kube-apiserver 注册的名为 <code>kubernetes</code> 的服务 IP (Service Cluster IP)，一般是 kube-apiserver <code>--service-cluster-ip-range</code> 选项值指定的网段的<strong>第一个IP</strong></li>
</ul>
<h4 id="生成kubernetes-证书和私钥："><a href="#生成kubernetes-证书和私钥：" class="headerlink" title="生成kubernetes 证书和私钥："></a>生成kubernetes 证书和私钥：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/apps/conf/kubernetes/ssl/ca.pem   -ca-key=/apps/conf/kubernetes/ssl/ca-key.pem   -config=/apps/conf/kubernetes/ssl/ca-config.json   -profile=kubernetes kubernetes-csr.json | cfssljson -bare kubernetes</span><br></pre></td></tr></table></figure>
<h4 id="配置和启动kube-apiserver"><a href="#配置和启动kube-apiserver" class="headerlink" title="配置和启动kube-apiserver"></a>配置和启动kube-apiserver</h4><h4 id="创建kube-apiserver-使用的客户端token-文件"><a href="#创建kube-apiserver-使用的客户端token-文件" class="headerlink" title="创建kube-apiserver 使用的客户端token 文件"></a>创建kube-apiserver 使用的客户端token 文件</h4><p>kubelet 首次启动时向kube-apiserver 发送TLS Bootstrapping 请求，kube-apiserver 验证请求中的token 是否与它配置的token.csv 一致，如果一致则自动为kubelet 生成证书和密钥。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /apps/conf/kubernetes/</span><br><span class="line">cat &gt; token.csv &lt;&lt;EOF</span><br><span class="line">$&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<h4 id="创建kube-apiserver-的systemd-unit文件"><a href="#创建kube-apiserver-的systemd-unit文件" class="headerlink" title="创建kube-apiserver 的systemd unit文件"></a>创建kube-apiserver 的systemd unit文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">cd /apps/sh</span><br><span class="line">cat  &gt; kube-apiserver.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/apps/svr/k8s/bin/kube-apiserver \\</span><br><span class="line">  --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota \\</span><br><span class="line">  --advertise-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --bind-address=0.0.0.0 \\</span><br><span class="line">  --insecure-bind-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --authorization-mode=Node,RBAC \\</span><br><span class="line">  --runtime-config=rbac.authorization.k8s.io/v1alpha1 \\</span><br><span class="line">  --kubelet-https=true \\</span><br><span class="line">  --enable-bootstrap-token-auth \\</span><br><span class="line">  --token-auth-file=/apps/conf/kubernetes/token.csv \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --service-node-port-range=$&#123;NODE_PORT_RANGE&#125; \\</span><br><span class="line">  --tls-cert-file=/apps/conf/kubernetes/ssl/kubernetes.pem \\</span><br><span class="line">  --tls-private-key-file=/apps/conf/kubernetes/ssl/kubernetes-key.pem \\</span><br><span class="line">  --client-ca-file=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --service-account-key-file=/apps/conf/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --etcd-cafile=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --etcd-certfile=/apps/conf/kubernetes/ssl/kubernetes.pem \\</span><br><span class="line">  --etcd-keyfile=/apps/conf/kubernetes/ssl/kubernetes-key.pem \\</span><br><span class="line">  --etcd-servers=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  --enable-swagger-ui=true \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --apiserver-count=2 \\</span><br><span class="line">  --audit-log-maxage=30 \\</span><br><span class="line">  --audit-log-maxbackup=3 \\</span><br><span class="line">  --audit-log-maxsize=100 \\</span><br><span class="line">  --audit-log-path=/apps/logs/kubernetes/audit.log \\</span><br><span class="line">  --audit-policy-file=/apps/conf/kubernetes/audit-policy.yaml \\</span><br><span class="line">  --event-ttl=1h \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=6</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>1.9.x</strong>版本的，一定要注意上面的参数<code>experimental-bootstrap-token-auth</code>，需要替换成<code>enable-bootstrap-token-auth</code>，因为这个参数在<strong>1.9.x</strong>里面已经废弃掉了</li>
<li>kube-apiserver 1.6 版本开始使用 etcd v3 API 和存储格式</li>
<li><code>--authorization-mode=RBAC</code> 指定在安全端口使用RBAC 授权模式，拒绝未通过授权的请求</li>
<li>kube-scheduler、kube-controller-manager 一般和 kube-apiserver 部署在同一台机器上，它们使用<strong>非安全端口</strong>和 kube-apiserver通信</li>
<li>kubelet、kube-proxy、kubectl 部署在其它 Node 节点上，如果通过<strong>安全端口</strong>访问 kube-apiserver，则必须先通过 TLS 证书认证，再通过 RBAC 授权</li>
<li>kube-proxy、kubectl 通过使用证书里指定相关的 User、Group 来达到通过 RBAC 授权的目的</li>
<li>如果使用了 kubelet TLS Boostrap 机制，则不能再指定 <code>--kubelet-certificate-authority</code>、<code>--kubelet-client-certificate</code> 和 <code>--kubelet-client-key</code> 选项，否则后续 kube-apiserver 校验 kubelet 证书时出现 ”x509: certificate signed by unknown authority“ 错误</li>
<li><code>--admission-control</code> 值必须包含 <code>ServiceAccount</code>，否则部署集群插件时会失败</li>
<li><code>--bind-address</code> 不能为 <code>127.0.0.1</code></li>
<li><code>--service-cluster-ip-range</code> 指定 Service Cluster IP 地址段，该地址段不能路由可达</li>
<li><code>--service-node-port-range=${NODE_PORT_RANGE}</code> 指定 NodePort 的端口范围</li>
<li>缺省情况下 kubernetes 对象保存在<code>etcd/registry</code> 路径下，可以通过 <code>--etcd-prefix</code> 参数进行调整</li>
<li>kube-apiserver 1.8版本后需要在<code>--authorization-mode</code>参数中添加<code>Node</code>，即：<code>--authorization-mode=Node,RBAC</code>，否则Node 节点无法注册</li>
<li>注意要开启审查日志功能，指定<code>--audit-log-path</code>参数是不够的，这只是指定了日志的路径，还需要指定一个审查日志策略文件：<code>--audit-policy-file</code>，我们也可以使用日志收集工具收集相关的日志进行分析</li>
</ul>
<p>新建文件 audit-policy.yaml</p>
<p>在目录/apps/conf/kubernetes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: audit.k8s.io/v1beta1 # This is required.</span><br><span class="line">kind: Policy</span><br><span class="line"># Don&apos;t generate audit events for all requests in RequestReceived stage.</span><br><span class="line">omitStages:</span><br><span class="line">  - &quot;RequestReceived&quot;</span><br><span class="line">rules:</span><br><span class="line">  # Log pod changes at RequestResponse level</span><br><span class="line">  - level: RequestResponse</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      # Resource &quot;pods&quot; doesn&apos;t match requests to any subresource of pods,</span><br><span class="line">      # which is consistent with the RBAC policy.</span><br><span class="line">      resources: [&quot;pods&quot;]</span><br><span class="line">  # Log &quot;pods/log&quot;, &quot;pods/status&quot; at Metadata level</span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      resources: [&quot;pods/log&quot;, &quot;pods/status&quot;]</span><br><span class="line"> </span><br><span class="line">  # Don&apos;t log requests to a configmap called &quot;controller-leader&quot;</span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot;</span><br><span class="line">      resources: [&quot;configmaps&quot;]</span><br><span class="line">      resourceNames: [&quot;controller-leader&quot;]</span><br><span class="line"> </span><br><span class="line">  # Don&apos;t log watch requests by the &quot;system:kube-proxy&quot; on endpoints or services</span><br><span class="line">  - level: None</span><br><span class="line">    users: [&quot;system:kube-proxy&quot;]</span><br><span class="line">    verbs: [&quot;watch&quot;]</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;endpoints&quot;, &quot;services&quot;]</span><br><span class="line"> </span><br><span class="line">  # Don&apos;t log authenticated requests to certain non-resource URL paths.</span><br><span class="line">  - level: None</span><br><span class="line">    userGroups: [&quot;system:authenticated&quot;]</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">    - &quot;/api*&quot; # Wildcard matching.</span><br><span class="line">    - &quot;/version&quot;</span><br><span class="line"> </span><br><span class="line">  # Log the request body of configmap changes in kube-system.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;configmaps&quot;]</span><br><span class="line">    # This rule only applies to resources in the &quot;kube-system&quot; namespace.</span><br><span class="line">    # The empty string &quot;&quot; can be used to select non-namespaced resources.</span><br><span class="line">    namespaces: [&quot;kube-system&quot;]</span><br><span class="line"> </span><br><span class="line">  # Log configmap and secret changes in all other namespaces at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">      resources: [&quot;secrets&quot;, &quot;configmaps&quot;]</span><br><span class="line"> </span><br><span class="line">  # Log all other resources in core and extensions at the Request level.</span><br><span class="line">  - level: Request</span><br><span class="line">    resources:</span><br><span class="line">    - group: &quot;&quot; # core API group</span><br><span class="line">    - group: &quot;extensions&quot; # Version of group should NOT be included.</span><br><span class="line"> </span><br><span class="line">  # A catch-all rule to log all other requests at the Metadata level.</span><br><span class="line">  - level: Metadata</span><br><span class="line">    # Long-running requests like watches that fall under this rule will not</span><br><span class="line">    # generate an audit event in RequestReceived.</span><br><span class="line">    omitStages:</span><br><span class="line">      - &quot;RequestReceived&quot;</span><br></pre></td></tr></table></figure>
<p>审查日志的相关配置可以查看文档了解：<a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a></p>
<h4 id="启动kube-apiserver"><a href="#启动kube-apiserver" class="headerlink" title="启动kube-apiserver"></a>启动kube-apiserver</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp kube-apiserver.service /etc/systemd/system/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver</span><br><span class="line">systemctl start kube-apiserver</span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>
<h4 id="配置和启动kube-controller-manager"><a href="#配置和启动kube-controller-manager" class="headerlink" title="配置和启动kube-controller-manager"></a>配置和启动kube-controller-manager</h4><h4 id="启动kube-controller-manager"><a href="#启动kube-controller-manager" class="headerlink" title="启动kube-controller-manager"></a>启动kube-controller-manager</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp kube-apiserver.service /etc/systemd/system/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-apiserver</span><br><span class="line">systemctl start kube-apiserver</span><br><span class="line">systemctl status kube-apiserver</span><br></pre></td></tr></table></figure>
<h4 id="配置和启动kube-scheduler"><a href="#配置和启动kube-scheduler" class="headerlink" title="配置和启动kube-scheduler"></a>配置和启动kube-scheduler</h4><h4 id="创建kube-scheduler-的systemd-unit文件"><a href="#创建kube-scheduler-的systemd-unit文件" class="headerlink" title="创建kube-scheduler 的systemd unit文件"></a>创建kube-scheduler 的systemd unit文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">[Service]</span><br><span class="line">ExecStart=/apps/svr/k8s/bin/kube-controller-manager \\</span><br><span class="line">  --address=127.0.0.1 \\</span><br><span class="line">  --master=http://$&#123;MASTER_URL&#125;:8080 \\</span><br><span class="line">  --allocate-node-cidrs=true \\</span><br><span class="line">  --service-cluster-ip-range=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --cluster-cidr=$&#123;CLUSTER_CIDR&#125; \\</span><br><span class="line">  --cluster-name=kubernetes \\</span><br><span class="line">  --cluster-signing-cert-file=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --cluster-signing-key-file=/apps/conf/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --service-account-private-key-file=/apps/conf/kubernetes/ssl/ca-key.pem \\</span><br><span class="line">  --root-ca-file=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  --leader-elect=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li><code>--address</code> 值必须为 <code>127.0.0.1</code>，因为当前 kube-apiserver 期望 scheduler 和 controller-manager 在同一台机器</li>
<li><code>--master=http://${MASTER_URL}:8080</code>：使用<code>http</code>(非安全端口)与 kube-apiserver 通信，需要下面的<code>haproxy</code>启动成功后才能去掉8080端口</li>
<li><code>--leader-elect=true</code> 部署多台机器组成的 master 集群时选举产生一处于工作状态的 <code>kube-controller-manager</code> 进程</li>
</ul>
<h3 id="启动kube-scheduler"><a href="#启动kube-scheduler" class="headerlink" title="启动kube-scheduler"></a>启动kube-scheduler</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cp kube-scheduler.service /etc/systemd/system/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-scheduler</span><br><span class="line">systemctl start kube-scheduler</span><br><span class="line">systemctl status kube-scheduler</span><br></pre></td></tr></table></figure>
<h2 id="6-4-验证master-节点"><a href="#6-4-验证master-节点" class="headerlink" title="6.4 验证master 节点"></a>6.4 验证master 节点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get componentstatuses</span><br></pre></td></tr></table></figure>
<p>NAME STATUS MESSAGE ERROR<br>controller-manager Healthy ok<br>scheduler Healthy ok<br>etcd-1 Healthy {“health”: “true”}<br>etcd-2 Healthy {“health”: “true”}<br>etcd-0 Healthy {“health”: “true”}</p>
<h3 id="关于k8s-master节点高可用"><a href="#关于k8s-master节点高可用" class="headerlink" title="关于k8s master节点高可用"></a>关于k8s master节点高可用</h3><p>目前所谓的 Kubernetes HA 其实主要的就是 API Server 的 HA，master 上其他组件比如 controller-manager 等都是可以通过 Etcd 做选举；而 API Server 只是提供一个请求接收服务，所以对于 API Server 一般有两种方式做 HA；一种是对多个 API Server 做 vip，另一种使用 nginx 反向代理，本文采用 nginx 方式</p>
<p><strong>master 之间除 api server 以外其他组件通过 etcd 选举，api server 默认不作处理；在每个 node 上启动一个 nginx，每个 nginx 反向代理所有 api server，node 上 kubelet、kube-proxy 连接本地的 nginx 代理端口，当 nginx 发现无法连接后端时会自动踢掉出问题的 api server，从而实现 api server 的 HA</strong></p>
<p>实际上是通过keepalived + haproxy实现的，其中keepalived是提供一个VIP，通过VIP关联所有的Master节点；然后haproxy提供端口转发功能。由于VIP还是存在Master的机器上的，默认配置API Server的端口是6443，所以我们需要将另外一个端口关联到这个VIP上，一般用8443。</p>
<p><code>haproxy</code>的确可以代理我们的两个master 上的apiserver 了，但是还不是高可用的，如果master01 这个节点down 掉了，那么我们haproxy 就不能正常提供服务了。这里我们可以使用两种方法来实现高可用</p>
<h4 id="方式1：使用阿里云SLB"><a href="#方式1：使用阿里云SLB" class="headerlink" title="方式1：使用阿里云SLB"></a>方式1：使用阿里云SLB</h4><p>这种方式实际上是最省心的，在阿里云上建一个内网的SLB，将master01 与master02 添加到SLB 机器组中，转发80(http)和443(https)端口即可（注意下面的提示）</p>
<blockquote>
<p>注意：阿里云的负载均衡是四层TCP负责，不支持后端ECS实例既作为Real Server又作为客户端向所在的负载均衡实例发送请求。因为返回的数据包只在云服务器内部转发，不经过负载均衡，所以在后端ECS实例上去访问负载均衡的服务地址是不通的。什么意思？就是如果你要使用阿里云的SLB的话，那么你不能在<code>apiserver</code>节点上使用SLB（比如在apiserver 上安装kubectl，然后将apiserver的地址设置为SLB的负载地址使用），因为这样的话就可能造成回环了，所以简单的做法是另外用两个新的节点做<code>HA</code>实例，然后将这两个实例添加到<code>SLB</code> 机器组中。</p>
</blockquote>
<h4 id="方式2：使用keepalived"><a href="#方式2：使用keepalived" class="headerlink" title="方式2：使用keepalived"></a>方式2：使用keepalived</h4><p><code>KeepAlived</code> 是一个高可用方案，通过 VIP（即虚拟 IP）和心跳检测来实现高可用。其原理是存在一组（两台）服务器，分别赋予 Master、Backup 两个角色，默认情况下Master 会绑定VIP 到自己的网卡上，对外提供服务。Master、Backup 会在一定的时间间隔向对方发送心跳数据包来检测对方的状态，这个时间间隔一般为 2 秒钟，如果Backup 发现Master 宕机，那么Backup 会发送ARP 包到网关，把VIP 绑定到自己的网卡，此时Backup 对外提供服务，实现自动化的故障转移，当Master 恢复的时候会重新接管服务。非常类似于路由器中的虚拟路由器冗余协议（VRRP）</p>
<h4 id="安装haproxy、keepalived"><a href="#安装haproxy、keepalived" class="headerlink" title="安装haproxy、keepalived"></a>安装haproxy、keepalived</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y haproxy keepalived</span><br></pre></td></tr></table></figure>
<h4 id="配置haproxy"><a href="#配置haproxy" class="headerlink" title="配置haproxy"></a>配置haproxy</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">frontend k8s-api</span><br><span class="line">    bind 192.168.1.137:443</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    tcp-request inspect-delay 5s</span><br><span class="line">    tcp-request content accept if &#123; req.ssl_hello_type 1 &#125;</span><br><span class="line">    default_backend k8s-api</span><br><span class="line"></span><br><span class="line">backend k8s-api</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    option tcp-check</span><br><span class="line">    balance roundrobin</span><br><span class="line">    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">    server k8s-api-1 192.168.1.137:6443 check</span><br><span class="line">    server k8s-api-2 192.168.1.138:6443 check</span><br><span class="line"></span><br><span class="line">frontend k8s-http-api</span><br><span class="line">    bind 192.168.1.137:80</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    default_backend k8s-http-api</span><br><span class="line"></span><br><span class="line">backend k8s-http-api</span><br><span class="line">    mode tcp</span><br><span class="line">    option tcplog</span><br><span class="line">    option tcp-check</span><br><span class="line">    balance roundrobin</span><br><span class="line">    default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">    server k8s-http-api-1 192.168.1.137:8080 check</span><br><span class="line">    server k8s-http-api-2 192.168.1.138:8080 check</span><br></pre></td></tr></table></figure>
<p>通过上面的配置文件我们可以看出通过<code>https</code>的访问将请求转发给apiserver 的6443端口了，http的请求转发到了apiserver 的8080端口。</p>
<h4 id="启动haproxy"><a href="#启动haproxy" class="headerlink" title="启动haproxy"></a>启动haproxy</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl start haproxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">enable</span> haproxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl status haproxy</span></span><br></pre></td></tr></table></figure>
<p>然后我们可以通过上面<code>9000</code>端口监控我们的<code>haproxy</code>的运行状态</p>
<p>上面我们的<code>haproxy</code>的确可以代理我们的两个master 上的apiserver 了，但是还不是高可用的，如果master01 这个节点down 掉了，那么我们haproxy 就不能正常提供服务了。这里我们可以使用两种方法来实现高可用</p>
<p><code>KeepAlived</code> 是一个高可用方案，通过 VIP（即虚拟 IP）和心跳检测来实现高可用。其原理是存在一组（两台）服务器，分别赋予 Master、Backup 两个角色，默认情况下Master 会绑定VIP 到自己的网卡上，对外提供服务。Master、Backup 会在一定的时间间隔向对方发送心跳数据包来检测对方的状态，这个时间间隔一般为 2 秒钟，如果Backup 发现Master 宕机，那么Backup 会发送ARP 包到网关，把VIP 绑定到自己的网卡，此时Backup 对外提供服务，实现自动化的故障转移，当Master 恢复的时候会重新接管服务。非常类似于路由器中的虚拟路由器冗余协议（VRRP）</p>
<p>我们这里将master01 设置为Master，master02 设置为Backup，修改配置：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> vi /etc/keepalived/keepalived.conf</span></span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">   &#125;</span><br><span class="line">   router_id kube_api</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_haproxy &#123;</span><br><span class="line">    # 自身状态检测</span><br><span class="line">    script "killall -0 haproxy"</span><br><span class="line">    interval 3</span><br><span class="line">    weight 5</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance haproxy-vip &#123;</span><br><span class="line">    # 使用单播通信，默认是组播通信</span><br><span class="line">    unicast_src_ip 192.168.1.137</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        192.168.1.138</span><br><span class="line">    &#125;</span><br><span class="line">    # 初始化状态</span><br><span class="line">    state MASTER</span><br><span class="line">    # 虚拟ip 绑定的网卡 （这里根据你自己的实际情况选择网卡）</span><br><span class="line">    interface eth0</span><br><span class="line">    # 此ID 要与Backup 配置一致</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    # 默认启动优先级，要比Backup 大点，但要控制量，保证自身状态检测生效</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        # 虚拟ip 地址</span><br><span class="line">        192.168.1.139</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_haproxy</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.1.139 80 &#123;</span><br><span class="line">  delay_loop 5</span><br><span class="line">  lvs_sched wlc</span><br><span class="line">  lvs_method NAT</span><br><span class="line">  persistence_timeout 1800</span><br><span class="line">  protocol TCP</span><br><span class="line"></span><br><span class="line">  real_server 192.168.1.137 80 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP_CHECK &#123;</span><br><span class="line">      connect_port 80</span><br><span class="line">      connect_timeout 3</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.1.139 443 &#123;</span><br><span class="line">  delay_loop 5</span><br><span class="line">  lvs_sched wlc</span><br><span class="line">  lvs_method NAT</span><br><span class="line">  persistence_timeout 1800</span><br><span class="line">  protocol TCP</span><br><span class="line"></span><br><span class="line">  real_server 192.168.1.137 443 &#123;</span><br><span class="line">    weight 1</span><br><span class="line">    TCP_CHECK &#123;</span><br><span class="line">      connect_port 443</span><br><span class="line">      connect_timeout 3</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>统一的方式在master02 节点上安装keepalived，修改配置，只需要将state 更改成BACKUP，priority更改成99，unicast_src_ip 与unicast_peer 地址修改即可。</p>
<p>启动keepalived:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> systemctl start keepalived</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl <span class="built_in">enable</span> keepalived</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看日志</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> journalctl -f -u keepalived</span></span><br></pre></td></tr></table></figure>
<p>验证虚拟IP:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用ifconfig -a 命令查看不到，要使用ip addr</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 00:16:3e:00:55:c1 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.1.137/24 brd 192.168.1.255 scope global dynamic eth0</span><br><span class="line">       valid_lft 31447746sec preferred_lft 31447746sec</span><br><span class="line">    inet 192.168.1.139/24 brd 192.168.1.255 scope global secondary eth0-vip</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure>
<blockquote>
<p>到这里，我们就可以将上面的6443端口和8080端口去掉了，可以手动将<code>kubectl</code>生成的<code>config</code>文件(<code>~/.kube/config</code>)中的server 地址6443端口去掉，另外<code>kube-controller-manager</code>和<code>kube-scheduler</code>的<strong>–master</strong>参数中的8080端口去掉了，然后分别重启这两个组件即可。</p>
</blockquote>
<p>验证apiserver：关闭master01 节点上的kube-apiserver 进程，然后查看虚拟ip是否漂移到了master02 节点。</p>
<p>然后我们就可以将第一步在<code>/etc/hosts</code>里面设置的域名对应的IP 更改为我们的虚拟IP了</p>
<blockquote>
<p>master01 与master 02 节点都需要安装keepalived 和haproxy，实际上我们虚拟IP的自身检测应该是检测haproxy，脚本大家可以自行更改</p>
</blockquote>
<p>这样我们就实现了接入层apiserver 的高可用了，一个部分是多活的apiserver 服务，另一个部分是一主一备的haproxy 服务。</p>
<h4 id="kube-controller-manager-和kube-scheduler-的高可用"><a href="#kube-controller-manager-和kube-scheduler-的高可用" class="headerlink" title="kube-controller-manager 和kube-scheduler 的高可用"></a>kube-controller-manager 和kube-scheduler 的高可用</h4><p>Kubernetes 的管理层服务包括<code>kube-scheduler</code>和<code>kube-controller-manager</code>。kube-scheduler和kube-controller-manager使用一主多从的高可用方案，在<strong>同一时刻只允许一个服务</strong>处以具体的任务。Kubernetes中实现了一套简单的选主逻辑，依赖Etcd实现scheduler和controller-manager的选主功能。如果scheduler和controller-manager在启动的时候设置了<code>leader-elect</code>参数，它们在启动后会先尝试获取leader节点身份，只有在获取leader节点身份后才可以执行具体的业务逻辑。它们分别会在Etcd中创建kube-scheduler和kube-controller-manager的endpoint，endpoint的信息中记录了当前的leader节点信息，以及记录的上次更新时间。leader节点会定期更新endpoint的信息，维护自己的leader身份。每个从节点的服务都会定期检查endpoint的信息，如果endpoint的信息在时间范围内没有更新，它们会尝试更新自己为leader节点。scheduler服务以及controller-manager服务之间不会进行通信，利用Etcd的强一致性，能够保证在分布式高并发情况下leader节点的全局唯一性。整体方案如下图所示：</p>
<p>当集群中的leader节点服务异常后，其它节点的服务会尝试更新自身为leader节点，当有多个节点同时更新endpoint时，由Etcd保证只有一个服务的更新请求能够成功。通过这种机制sheduler和controller-manager可以保证在leader节点宕机后其它的节点可以顺利选主，保证服务故障后快速恢复。当集群中的网络出现故障时对服务的选主影响不是很大，因为scheduler和controller-manager是依赖Etcd进行选主的，在网络故障后，可以和Etcd通信的主机依然可以按照之前的逻辑进行选主，就算集群被切分，Etcd也可以保证同一时刻只有一个节点的服务处于leader状态。</p>
<h3 id="k8s-Node节点安装flannel网络"><a href="#k8s-Node节点安装flannel网络" class="headerlink" title="k8s Node节点安装flannel网络"></a>k8s Node节点安装flannel网络</h3><p>kubernetes 要求集群内各节点能通过Pod 网段互联互通，下面我们来使用Flannel 在所有节点上创建互联互通的Pod 网段的步骤。</p>
<h4 id="创建TLS-密钥和证书-1"><a href="#创建TLS-密钥和证书-1" class="headerlink" title="创建TLS 密钥和证书"></a>创建TLS 密钥和证书</h4><p>etcd 集群启用了双向TLS 认证，所以需要为flanneld 指定与etcd 集群通信的CA 和密钥。</p>
<p>创建flanneld 证书签名请求：</p>
<p>新建目录/apps/conf/flanneld/ssl</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; flanneld-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;flanneld&quot;,</span><br><span class="line">  &quot;hosts&quot;: [],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;BeiJing&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>生成flanneld 证书和私钥：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=/apps/conf/kubernetes/ssl/ca.pem   -ca-key=/apps/conf/kubernetes/ssl/ca-key.pem   -config=/apps/conf/kubernetes/ssl/ca-config.json   -profile=kubernetes flanneld-csr.json | cfssljson -bare flanneld</span><br></pre></td></tr></table></figure>
<h4 id="向etcd-写入集群Pod-网段信息"><a href="#向etcd-写入集群Pod-网段信息" class="headerlink" title="向etcd 写入集群Pod 网段信息"></a>向etcd 写入集群Pod 网段信息</h4><p>该步骤只需在第一次部署Flannel 网络时执行，后续在其他节点上部署Flanneld 时无需再写入该信息</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">etcdctl   --endpoints=$&#123;ETCD_ENDPOINTS&#125;   --ca-file=/apps/conf/kubernetes/ssl/ca.pem   --cert-file=/apps/conf/flanneld/ssl/flanneld.pem   --key-file=/apps/conf/flanneld/ssl/flanneld-key.pem   set $&#123;FLANNEL_ETCD_PREFIX&#125;/config &apos;&#123;&quot;Network&quot;:&quot;&apos;$&#123;CLUSTER_CIDR&#125;&apos;&quot;, &quot;SubnetLen&quot;: 24, &quot;Backend&quot;: &#123;&quot;Type&quot;: &quot;vxlan&quot;&#125;&#125;&apos;</span><br></pre></td></tr></table></figure>
<p>写入的 Pod 网段(${CLUSTER_CIDR}，10.200.0.0/16) 必须与<code>kube-controller-manager</code> 的 <code>--cluster-cidr</code> 选项值一致；</p>
<p>创建flanneld的systemd unit 文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cd /apps/sh</span><br><span class="line">cat &gt; flanneld.service &lt;&lt; EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Flanneld overlay address etcd agent</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=etcd.service</span><br><span class="line">Before=docker.service</span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/apps/svr/k8s/bin/flanneld \\</span><br><span class="line">  -etcd-cafile=/apps/conf/kubernetes/ssl/ca.pem \\</span><br><span class="line">  -etcd-certfile=/apps/conf/flanneld/ssl/flanneld.pem \\</span><br><span class="line">  -etcd-keyfile=/apps/conf/flanneld/ssl/flanneld-key.pem \\</span><br><span class="line">  -etcd-endpoints=$&#123;ETCD_ENDPOINTS&#125; \\</span><br><span class="line">  -etcd-prefix=$&#123;FLANNEL_ETCD_PREFIX&#125;</span><br><span class="line">ExecStartPost=/apps/svr/k8s/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</span><br><span class="line">Restart=on-failure</span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">RequiredBy=docker.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li><code>mk-docker-opts.sh</code>脚本将分配给flanneld 的Pod 子网网段信息写入到<code>/run/flannel/docker</code> 文件中，后续docker 启动时使用这个文件中的参数值为 docker0 网桥</li>
<li>flanneld 使用系统缺省路由所在的接口和其他节点通信，对于有多个网络接口的机器(内网和公网)，可以用 <code>--iface</code> 选项值指定通信接口(上面的 systemd unit 文件没指定这个选项)</li>
</ul>
<h4 id="启动flanneld"><a href="#启动flanneld" class="headerlink" title="启动flanneld"></a>启动flanneld</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp flanneld.service /etc/systemd/system/</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable flanneld</span><br><span class="line">systemctl start flanneld</span><br></pre></td></tr></table></figure>
<h4 id="检查flanneld-服务"><a href="#检查flanneld-服务" class="headerlink" title="检查flanneld 服务"></a>检查flanneld 服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig flannel.1</span><br></pre></td></tr></table></figure>
<h4 id="检查分配给各flanneld-的Pod-网段信息"><a href="#检查分配给各flanneld-的Pod-网段信息" class="headerlink" title="检查分配给各flanneld 的Pod 网段信息"></a>检查分配给各flanneld 的Pod 网段信息</h4><p>查看集群 Pod 网段(/16)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">etcdctl \</span><br><span class="line"> --endpoints=$&#123;ETCD_ENDPOINTS&#125; \</span><br><span class="line"> --ca-file=/apps/conf/kubernetes/ssl/ca.pem \</span><br><span class="line"> --cert-file=/apps/conf/flanneld/ssl/flanneld.pem \</span><br><span class="line"> --key-file=/apps/conf/flanneld/ssl/flanneld-key.pem \</span><br><span class="line"> get $&#123;FLANNEL_ETCD_PREFIX&#125;/config</span><br></pre></td></tr></table></figure>
<p>{“Network”:”10.200.0.0/16”, “SubnetLen”: 24, “Backend”: {“Type”: “vxlan”}}</p>
<h3 id="部署-K8s-Node节点"><a href="#部署-K8s-Node节点" class="headerlink" title="部署 K8s Node节点"></a>部署 K8s Node节点</h3><p>kubernetes Node 节点包含如下组件：</p>
<ul>
<li>flanneld</li>
<li>docker</li>
<li>kubelet</li>
<li>kube-proxy</li>
</ul>
<h4 id="安装Docker基础环境"><a href="#安装Docker基础环境" class="headerlink" title="安装Docker基础环境"></a>安装Docker基础环境</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line">yum install docker-ce -y</span><br><span class="line">systemctl start docker &amp;&amp; systemctl enable docker</span><br></pre></td></tr></table></figure>
<h4 id="配置docker"><a href="#配置docker" class="headerlink" title="配置docker"></a>配置docker</h4><p>你可以用二进制或yum install 的方式来安装docker，然后修改docker 的systemd unit 文件：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /usr/lib/systemd/system/docker.service  <span class="comment"># 用systemctl status docker 命令可查看unit 文件路径</span></span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line"><span class="meta">#</span><span class="bash"> the default is not to use systemd <span class="keyword">for</span> cgroups because the delegate issues still</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> exists and systemd currently does not support the cgroup feature <span class="built_in">set</span> required</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">for</span> containers run by docker</span></span><br><span class="line">EnvironmentFile=-/run/flannel/docker</span><br><span class="line">ExecStart=/usr/bin/dockerd --log-level=info $DOCKER_NETWORK_OPTIONS</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line"><span class="meta">#</span><span class="bash"> Having non-zero Limit*s causes performance problems due to accounting overhead</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">in</span> the kernel. We recommend using cgroups to <span class="keyword">do</span> container-local accounting.</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">LimitCORE=infinity</span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment TasksMax <span class="keyword">if</span> your systemd version supports it.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Only systemd 226 and above support this version.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">TasksMax=infinity</span></span><br><span class="line">TimeoutStartSec=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> delegate yes so that systemd does not reset the cgroups of docker containers</span></span><br><span class="line">Delegate=yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">kill</span> only the docker process, not all processes <span class="keyword">in</span> the cgroup</span></span><br><span class="line">KillMode=process</span><br><span class="line"><span class="meta">#</span><span class="bash"> restart the docker process <span class="keyword">if</span> it exits prematurely</span></span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<ul>
<li>dockerd 运行时会调用其它 docker 命令，如 docker-proxy，所以需要将 docker 命令所在的目录加到 PATH 环境变量中</li>
<li>flanneld 启动时将网络配置写入到 <code>/run/flannel/docker</code> 文件中的变量 <code>DOCKER_NETWORK_OPTIONS</code>，dockerd 命令行上指定该变量值来设置 docker0 网桥参数</li>
<li>如果指定了多个 <code>EnvironmentFile</code> 选项，则必须将 <code>/run/flannel/docker</code> 放在最后(确保 docker0 使用 flanneld 生成的 bip 参数)</li>
<li>不能关闭默认开启的 <code>--iptables</code> 和 <code>--ip-masq</code> 选项</li>
<li>如果内核版本比较新，建议使用 <code>overlay</code> 存储驱动</li>
<li>docker 从 1.13 版本开始，可能将 <strong>iptables FORWARD chain的默认策略设置为DROP</strong>，从而导致 ping 其它 Node 上的 Pod IP 失败，遇到这种情况时，需要手动设置策略为 <code>ACCEPT</code>：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo iptables -P FORWARD ACCEPT</span></span><br></pre></td></tr></table></figure>
<p>如果没有开启上面的路由转发(<code>net.ipv4.ip_forward=1</code>)，则需要把以下命令写入<code>/etc/rc.local</code>文件中，防止节点重启<strong>iptables FORWARD chain的默认策略又还原为DROP</strong>（下面的开机脚本我测试了几次都没生效，不知道是不是方法有误，所以最好的方式还是开启上面的路由转发功能，一劳永逸）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sleep 60 &amp;&amp; /sbin/iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure>
<ul>
<li>为了加快 pull image 的速度，可以使用国内的仓库镜像服务器，同时增加下载的并发数。(如果 dockerd 已经运行，则需要重启 dockerd 生效。)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat /etc/docker/daemon.json</span></span><br><span class="line">&#123;</span><br><span class="line">  "max-concurrent-downloads": 10</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl daemon-reload</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl stop firewalld</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">disable</span> firewalld</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo iptables -F &amp;&amp; sudo iptables -X &amp;&amp; sudo iptables -F -t nat &amp;&amp; sudo iptables -X -t nat</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">enable</span> docker</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl start docker</span></span><br></pre></td></tr></table></figure>
<ul>
<li>需要关闭 firewalld(centos7)/ufw(ubuntu16.04)，否则可能会重复创建 iptables 规则</li>
<li>最好清理旧的 iptables rules 和 chains 规则</li>
<li>执行命令：docker version，检查docker服务是否正常</li>
</ul>
<h3 id="安装和配置kubelet"><a href="#安装和配置kubelet" class="headerlink" title="安装和配置kubelet"></a>安装和配置kubelet</h3><p>kubelet 启动时向kube-apiserver 发送TLS bootstrapping 请求，需要先将bootstrap token 文件中的kubelet-bootstrap 用户赋予system:node-bootstrapper 角色，然后kubelet 才有权限创建认证请求(certificatesigningrequests)：</p>
<blockquote>
<p>kubelet就是运行在Node节点上的，所以这一步安装是在所有的Node节点上，如果你想把你的Master也当做Node节点的话，当然也可以在Master节点上安装的。</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>--user=kubelet-bootstrap</code> 是文件 <code>/etc/kubernetes/token.csv</code> 中指定的用户名，同时也写入了文件 <code>/etc/kubernetes/bootstrap.kubeconfig</code></li>
</ul>
<p>另外1.8 版本中还需要为Node 请求创建一个RBAC 授权规则：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create clusterrolebinding kubelet-nodes --clusterrole=system:node --group=system:nodes</span></span><br></pre></td></tr></table></figure>
<p>然后下载最新的kubelet 和kube-proxy 二进制文件（前面下载kubernetes 目录下面其实也有）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> wget https://dl.k8s.io/v1.8.2/kubernetes-server-linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar -xzvf kubernetes-server-linux-amd64.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> kubernetes</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> tar -xzvf  kubernetes-src.tar.gz</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo cp -r ./server/bin/&#123;kube-proxy,kubelet&#125; /usr/k8s/bin/</span></span><br></pre></td></tr></table></figure>
<h3 id="创建kubelet-bootstapping-kubeconfig-文件"><a href="#创建kubelet-bootstapping-kubeconfig-文件" class="headerlink" title="创建kubelet bootstapping kubeconfig 文件"></a>创建kubelet bootstapping kubeconfig 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置集群参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-cluster kubernetes \</span></span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置客户端认证参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-credentials kubelet-bootstrap \</span></span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置上下文参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-context default \</span></span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置默认上下文</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv bootstrap.kubeconfig /etc/kubernetes/</span></span><br></pre></td></tr></table></figure>
<ul>
<li><code>--embed-certs</code> 为 <code>true</code> 时表示将 <code>certificate-authority</code> 证书写入到生成的 <code>bootstrap.kubeconfig</code> 文件中；</li>
<li>设置 kubelet 客户端认证参数时<strong>没有</strong>指定秘钥和证书，后续由 <code>kube-apiserver</code> 自动生成；</li>
</ul>
<h3 id="创建kubelet-的systemd-unit-文件"><a href="#创建kubelet-的systemd-unit-文件" class="headerlink" title="创建kubelet 的systemd unit 文件"></a>创建kubelet 的systemd unit 文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir /var/lib/kubelet <span class="comment"># 必须先创建工作目录</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; kubelet.service &lt;&lt;EOF</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">ExecStart=/usr/k8s/bin/kubelet \\</span><br><span class="line">  --fail-swap-on=false \\</span><br><span class="line">  --cgroup-driver=cgroupfs \\</span><br><span class="line">  --address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --hostname-override=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --experimental-bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><br><span class="line">  --require-kubeconfig \\</span><br><span class="line">  --cert-dir=/etc/kubernetes/ssl \\</span><br><span class="line">  --cluster-dns=$&#123;CLUSTER_DNS_SVC_IP&#125; \\</span><br><span class="line">  --cluster-domain=$&#123;CLUSTER_DNS_DOMAIN&#125; \\</span><br><span class="line">  --hairpin-mode promiscuous-bridge \\</span><br><span class="line">  --allow-privileged=true \\</span><br><span class="line">  --serialize-image-pulls=false \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>请仔细阅读下面的注意事项，不然可能会启动失败</strong>。</p>
</blockquote>
<ul>
<li><code>--fail-swap-on</code>参数，这个一定要注意，<strong>Kubernetes 1.8开始要求关闭系统的Swap</strong>，如果不关闭，默认配置下kubelet将无法启动，也可以通过kubelet的启动参数<code>–fail-swap-on=false</code>来避免该问题</li>
<li><code>--cgroup-driver</code>参数，kubelet 用来维护主机的的 cgroups 的，默认是<code>cgroupfs</code>，但是这个地方的值需要你根据docker 的配置来确定（<code>docker info |grep cgroup</code>）</li>
<li><code>-address</code> 不能设置为 <code>127.0.0.1</code>，否则后续 Pods 访问 kubelet 的 API 接口时会失败，因为 Pods 访问的 <code>127.0.0.1</code>指向自己而不是 kubelet</li>
<li>如果设置了 <code>--hostname-override</code> 选项，则 <code>kube-proxy</code> 也需要设置该选项，否则会出现找不到 Node 的情况</li>
<li><code>--experimental-bootstrap-kubeconfig</code> 指向 bootstrap kubeconfig 文件，kubelet 使用该文件中的用户名和 token 向 kube-apiserver 发送 TLS Bootstrapping 请求</li>
<li>管理员通过了 CSR 请求后，kubelet 自动在 <code>--cert-dir</code> 目录创建证书和私钥文件(<code>kubelet-client.crt</code> 和 <code>kubelet-client.key</code>)，然后写入 <code>--kubeconfig</code> 文件(自动创建 <code>--kubeconfig</code> 指定的文件)</li>
<li>建议在 <code>--kubeconfig</code> 配置文件中指定 <code>kube-apiserver</code> 地址，如果未指定 <code>--api-servers</code> 选项，则必须指定 <code>--require-kubeconfig</code> 选项后才从配置文件中读取 kue-apiserver 的地址，否则 kubelet 启动后将找不到 kube-apiserver (日志中提示未找到 API Server），<code>kubectl get nodes</code> 不会返回对应的 Node 信息</li>
<li><code>--cluster-dns</code> 指定 kubedns 的 Service IP(可以先分配，后续创建 kubedns 服务时指定该 IP)，<code>--cluster-domain</code> 指定域名后缀，这两个参数同时指定后才会生效</li>
</ul>
<h3 id="启动kubelet"><a href="#启动kubelet" class="headerlink" title="启动kubelet"></a>启动kubelet</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo cp kubelet.service /etc/systemd/system/kubelet.service</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl daemon-reload</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">enable</span> kubelet</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl start kubelet</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl status kubelet</span></span><br></pre></td></tr></table></figure>
<h3 id="通过kubelet-的TLS-证书请求"><a href="#通过kubelet-的TLS-证书请求" class="headerlink" title="通过kubelet 的TLS 证书请求"></a>通过kubelet 的TLS 证书请求</h3><p>kubelet 首次启动时向kube-apiserver 发送证书签名请求，必须通过后kubernetes 系统才会将该 Node 加入到集群。查看未授权的CSR 请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get csr</span></span><br><span class="line">NAME                                                   AGE       REQUESTOR           CONDITION</span><br><span class="line">node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g   2m        kubelet-bootstrap   Pending</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure>
<p>通过CSR 请求：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl certificate approve node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g</span></span><br><span class="line">certificatesigningrequest "node-csr--k3G2G1EoM4h9w1FuJRjJjfbIPNxa551A8TZfW9dG-g" approved</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get nodes</span></span><br><span class="line">NAME            STATUS    ROLES     AGE       VERSION</span><br><span class="line">192.168.1.170   Ready     &lt;none&gt;    48s       v1.8.1</span><br></pre></td></tr></table></figure>
<p>自动生成了kubelet kubeconfig 文件和公私钥：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> ls -l /etc/kubernetes/kubelet.kubeconfig</span></span><br><span class="line">-rw------- 1 root root 2280 Nov  7 10:26 /etc/kubernetes/kubelet.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> ls -l /etc/kubernetes/ssl/kubelet*</span></span><br><span class="line">-rw-r--r-- 1 root root 1046 Nov  7 10:26 /etc/kubernetes/ssl/kubelet-client.crt</span><br><span class="line">-rw------- 1 root root  227 Nov  7 10:22 /etc/kubernetes/ssl/kubelet-client.key</span><br><span class="line">-rw-r--r-- 1 root root 1115 Nov  7 10:16 /etc/kubernetes/ssl/kubelet.crt</span><br><span class="line">-rw------- 1 root root 1675 Nov  7 10:16 /etc/kubernetes/ssl/kubelet.key</span><br></pre></td></tr></table></figure>
<h3 id="配置kube-proxy"><a href="#配置kube-proxy" class="headerlink" title="配置kube-proxy"></a>配置kube-proxy</h3><h4 id="创建kube-proxy-证书签名请求："><a href="#创建kube-proxy-证书签名请求：" class="headerlink" title="创建kube-proxy 证书签名请求："></a>创建kube-proxy 证书签名请求：</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span></span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-proxy",</span><br><span class="line">  "hosts": [],</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "BeiJing",</span><br><span class="line">      "L": "BeiJing",</span><br><span class="line">      "O": "k8s",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li>CN 指定该证书的 User 为 <code>system:kube-proxy</code></li>
<li><code>kube-apiserver</code> 预定义的 RoleBinding <code>system:node-proxier</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code>绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
<li>hosts 属性值为空列表</li>
</ul>
<h4 id="生成kube-proxy-客户端证书和私钥"><a href="#生成kube-proxy-客户端证书和私钥" class="headerlink" title="生成kube-proxy 客户端证书和私钥"></a>生成kube-proxy 客户端证书和私钥</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \</span></span><br><span class="line">  -ca-key=/etc/kubernetes/ssl/ca-key.pem \</span><br><span class="line">  -config=/etc/kubernetes/ssl/ca-config.json \</span><br><span class="line">  -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br><span class="line"><span class="meta">$</span><span class="bash"> ls kube-proxy*</span></span><br><span class="line">kube-proxy.csr  kube-proxy-csr.json  kube-proxy-key.pem  kube-proxy.pem</span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo mv kube-proxy*.pem /etc/kubernetes/ssl/</span></span><br></pre></td></tr></table></figure>
<h4 id="创建kube-proxy-kubeconfig-文件"><a href="#创建kube-proxy-kubeconfig-文件" class="headerlink" title="创建kube-proxy kubeconfig 文件"></a>创建kube-proxy kubeconfig 文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置集群参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-cluster kubernetes \</span></span><br><span class="line">  --certificate-authority=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置客户端认证参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-credentials kube-proxy \</span></span><br><span class="line">  --client-certificate=/etc/kubernetes/ssl/kube-proxy.pem \</span><br><span class="line">  --client-key=/etc/kubernetes/ssl/kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置上下文参数</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config <span class="built_in">set</span>-context default \</span></span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="comment"># 设置默认上下文</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> mv kube-proxy.kubeconfig /etc/kubernetes/</span></span><br></pre></td></tr></table></figure>
<ul>
<li>设置集群参数和客户端认证参数时 <code>--embed-certs</code> 都为 <code>true</code>，这会将 <code>certificate-authority</code>、<code>client-certificate</code> 和 <code>client-key</code> 指向的证书文件内容写入到生成的 <code>kube-proxy.kubeconfig</code> 文件中</li>
<li><code>kube-proxy.pem</code> 证书中 CN 为 <code>system:kube-proxy</code>，<code>kube-apiserver</code> 预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="创建kube-proxy-的systemd-unit-文件"><a href="#创建kube-proxy-的systemd-unit-文件" class="headerlink" title="创建kube-proxy 的systemd unit 文件"></a>创建kube-proxy 的systemd unit 文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo mkdir -p /var/lib/kube-proxy <span class="comment"># 必须先创建工作目录</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cat &gt; kube-proxy.service &lt;&lt;EOF</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kube-proxy</span><br><span class="line">ExecStart=/usr/k8s/bin/kube-proxy \\</span><br><span class="line">  --bind-address=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --hostname-override=$&#123;NODE_IP&#125; \\</span><br><span class="line">  --cluster-cidr=$&#123;SERVICE_CIDR&#125; \\</span><br><span class="line">  --kubeconfig=/etc/kubernetes/kube-proxy.kubeconfig \\</span><br><span class="line">  --logtostderr=true \\</span><br><span class="line">  --v=2</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<ul>
<li><code>--hostname-override</code> 参数值必须与 kubelet 的值一致，否则 kube-proxy 启动后会找不到该 Node，从而不会创建任何 iptables 规则</li>
<li><code>--cluster-cidr</code> 必须与 kube-apiserver 的 <code>--service-cluster-ip-range</code> 选项值一致</li>
<li>kube-proxy 根据 <code>--cluster-cidr</code> 判断集群内部和外部流量，指定 <code>--cluster-cidr</code> 或 <code>--masquerade-all</code> 选项后 kube-proxy 才会对访问 Service IP 的请求做 SNAT</li>
<li><code>--kubeconfig</code> 指定的配置文件嵌入了 kube-apiserver 的地址、用户名、证书、秘钥等请求和认证信息</li>
<li>预定义的 RoleBinding <code>cluster-admin</code> 将User <code>system:kube-proxy</code> 与 Role <code>system:node-proxier</code> 绑定，该 Role 授予了调用 <code>kube-apiserver</code> Proxy 相关 API 的权限</li>
</ul>
<h4 id="启动kube-proxy"><a href="#启动kube-proxy" class="headerlink" title="启动kube-proxy"></a>启动kube-proxy</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> sudo cp kube-proxy.service /etc/systemd/system/</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl daemon-reload</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl <span class="built_in">enable</span> kube-proxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo systemctl start kube-proxy</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> systemctl status kube-proxy</span></span><br></pre></td></tr></table></figure>
<h3 id="验证集群功能"><a href="#验证集群功能" class="headerlink" title="验证集群功能"></a>验证集群功能</h3><p>定义yaml 文件：（将下面内容保存为：nginx-ds.yaml）</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">http</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">80</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="number">80</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx-ds</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">my-nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">nginx:1.7.9</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>创建 Pod 和服务：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl create -f nginx-ds.yml</span></span><br><span class="line">service "nginx-ds" created</span><br><span class="line">daemonset "nginx-ds" created</span><br></pre></td></tr></table></figure>
<p>执行下面的命令查看Pod 和SVC：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> kubectl get pods -o wide</span></span><br><span class="line">NAME             READY     STATUS    RESTARTS   AGE       IP           NODE</span><br><span class="line">nginx-ds-f29zt   1/1       Running   0          23m       172.17.0.2   192.168.1.170</span><br><span class="line"><span class="meta">$</span><span class="bash"> kubectl get svc</span></span><br><span class="line">NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE</span><br><span class="line">nginx-ds     NodePort    10.254.6.249   &lt;none&gt;        80:30813/TCP   24m</span><br></pre></td></tr></table></figure>
<p>可以看到：</p>
<ul>
<li>服务IP：10.254.6.249</li>
<li>服务端口：80</li>
<li>NodePort端口：30813</li>
</ul>
<p>在所有 Node 上执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ curl 10.254.6.249</span><br><span class="line">$ curl 192.168.1.170:30813</span><br></pre></td></tr></table></figure>
<p>执行上面的命令预期都会输出nginx 欢迎页面内容，表示我们的Node 节点正常运行了。</p>
<h3 id="解决从k8s-gcr-io拉取镜像失败问题"><a href="#解决从k8s-gcr-io拉取镜像失败问题" class="headerlink" title="解决从k8s.gcr.io拉取镜像失败问题"></a>解决从k8s.gcr.io拉取镜像失败问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker pull mirrorgooglecontainers/kube-apiserver-amd64:v1.11.3</span><br><span class="line">docker pull mirrorgooglecontainers/kube-controller-manager-amd64:v1.11.3</span><br><span class="line">docker pull mirrorgooglecontainers/kube-scheduler-amd64:v1.11.3</span><br><span class="line">docker pull mirrorgooglecontainers/kube-proxy-amd64:v1.11.3</span><br><span class="line">docker pull mirrorgooglecontainers/pause:3.1</span><br><span class="line">docker pull mirrorgooglecontainers/etcd-amd64:3.2.18</span><br><span class="line">docker pull coredns/coredns:1.1.3</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker tag docker.io/mirrorgooglecontainers/kube-proxy-amd64:v1.11.3 k8s.gcr.io/kube-proxy-amd64:v1.11.3</span><br><span class="line">docker tag docker.io/mirrorgooglecontainers/kube-scheduler-amd64:v1.11.3 k8s.gcr.io/kube-scheduler-amd64:v1.11.3</span><br><span class="line">docker tag docker.io/mirrorgooglecontainers/kube-apiserver-amd64:v1.11.3 k8s.gcr.io/kube-apiserver-amd64:v1.11.3</span><br><span class="line">docker tag docker.io/mirrorgooglecontainers/kube-controller-manager-amd64:v1.11.3 k8s.gcr.io/kube-controller-manager-amd64:v1.11.3</span><br><span class="line">docker tag docker.io/mirrorgooglecontainers/etcd-amd64:3.2.18  k8s.gcr.io/etcd-amd64:3.2.18</span><br><span class="line">docker tag docker.io/mirrorgooglecontainers/pause:3.1  k8s.gcr.io/pause:3.1</span><br><span class="line">docker tag docker.io/coredns/coredns:1.1.3  k8s.gcr.io/coredns:1.1.3</span><br></pre></td></tr></table></figure>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<ul>
<li><a href="https://www.qikqiak.com/post/manual-install-high-available-kubernetes-cluster/" target="_blank" rel="noopener">https://www.qikqiak.com/post/manual-install-high-available-kubernetes-cluster/</a></li>
<li><a href="https://github.com/mendickxiao/kubeasz/blob/master/docs/00-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92%E5%92%8C%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A.md" target="_blank" rel="noopener">https://github.com/mendickxiao/kubeasz/blob/master/docs/00-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92%E5%92%8C%E5%9F%BA%E7%A1%80%E5%8F%82%E6%95%B0%E8%AE%BE%E5%AE%9A.md</a></li>
<li><a href="https://jimmysong.io/kubernetes-handbook/practice/master-ha.html" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook/practice/master-ha.html#</a></li>
<li><a href="https://www.kubernetes.org.cn/5025.html" target="_blank" rel="noopener">https://www.kubernetes.org.cn/5025.html</a></li>
<li><a href="https://www.kubernetes.org.cn/4963.html" target="_blank" rel="noopener">https://www.kubernetes.org.cn/4963.html</a></li>
<li><a href="https://k8s-install.opsnull.com/01.%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F.html" target="_blank" rel="noopener">https://k8s-install.opsnull.com/01.%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96%E5%92%8C%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F.html</a></li>
<li><a href="https://kubernetes.feisky.xyz/bu-shu-pei-zhi/index" target="_blank" rel="noopener">https://kubernetes.feisky.xyz/bu-shu-pei-zhi/index</a></li>
<li><a href="https://mritd.me/2017/07/21/set-up-kubernetes-ha-cluster-by-binary/" target="_blank" rel="noopener">https://mritd.me/2017/07/21/set-up-kubernetes-ha-cluster-by-binary/</a></li>
</ul>
</blockquote>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2019-04-23T08:25:06.129Z" itemprop="dateUpdated">2019-04-23 16:25:06</time>
</span><br>


        
    </div>
    
    <footer>
        <a href="https://yo42.github.io">
            <img src="/img/yo.jpg" alt="Neo">
            Neo
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Technology/">Technology</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://yo42.github.io/2019/01/29/搭建k8s集群/&title=《手动搭建k8s集群》 — Neo42&pic=https://yo42.github.io/img/yo.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://yo42.github.io/2019/01/29/搭建k8s集群/&title=《手动搭建k8s集群》 — Neo42&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://yo42.github.io/2019/01/29/搭建k8s集群/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《手动搭建k8s集群》 — Neo42&url=https://yo42.github.io/2019/01/29/搭建k8s集群/&via=https://yo42.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://yo42.github.io/2019/01/29/搭建k8s集群/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between">
  
    <div class="waves-block waves-effect prev">
      <a href="/2019/02/14/使用kubeasz搭建K8s集群/" id="post-prev" class="post-nav-link">
        <div class="tips"><i class="icon icon-angle-left icon-lg icon-pr"></i> Prev</div>
        <h4 class="title">使用kubeasz搭建K8s集群</h4>
      </a>
    </div>
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/10/28/DevOps-SRE-必备技能清单/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">DevOps &amp; SRE 必备技能清单</h4>
      </a>
    </div>
  
</nav>



    

















</article>



</div>

        <footer class="footer">
    <div class="top">
        

        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Neo &copy; 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> 
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://yo42.github.io/2019/01/29/搭建k8s集群/&title=《手动搭建k8s集群》 — Neo42&pic=https://yo42.github.io/img/yo.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://yo42.github.io/2019/01/29/搭建k8s集群/&title=《手动搭建k8s集群》 — Neo42&source=" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://yo42.github.io/2019/01/29/搭建k8s集群/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《手动搭建k8s集群》 — Neo42&url=https://yo42.github.io/2019/01/29/搭建k8s集群/&via=https://yo42.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://yo42.github.io/2019/01/29/搭建k8s集群/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=https://yo42.github.io/2019/01/29/搭建k8s集群/" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>










<script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>